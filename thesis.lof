\select@language {british}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The HRI taxonomy proposed by Beer et al.\citep {Beer2014}. Adapted and reprinted from \citep {Beer2014}.\relax }}{25}{figure.caption.5}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces The pioneer-3DX robot used in the experiment, equipped with a laser range finder and a camera.\relax }}{42}{figure.caption.6}
\contentsline {figure}{\numberline {3.2}{\ignorespaces The control interface as presented to the operator. \textbf {Top}: video feed from the camera and the map of the environment. Inside the map, the position of the robot is visualized by the 3D model, the current goal by the blue arrow, the AI planned path by the green line, the obstacles' laser reflections by red and map walls with black. \textbf {Bottom}: the current autonomy mode, secondary task, and the status of the robot. \relax }}{42}{figure.caption.7}
\contentsline {figure}{\numberline {3.3}{\ignorespaces \textbf {Left}: the maze-like arena used in the experiment. \textbf {Right}: a SLAM map of the arena constructed using the robot's onboard laser, and displayed to the human operator on the OCU. Operators are asked to drive from point A to point B and then back again to point A.\relax }}{45}{figure.caption.8}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Red is high load, blue is low.\relax }}{47}{figure.caption.9}
\contentsline {figure}{\numberline {3.5}{\ignorespaces In \ref {subfig:primary_score_pilot} red is high load, blue is low.\relax }}{48}{figure.caption.10}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Secondary task performance. Red is high load, blue is low.\relax }}{49}{figure.caption.11}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The control interface as presented to the operator. \textbf {Left}: video feed from the camera, the control mode in use and the status of the robot. \textbf {Right}: The map showing the position of the robot, the current goal (blue arrow), the AI planned path (green line), the obstacles' laser reflections (red) and the walls (black).\relax }}{58}{figure.caption.13}
\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf {\ref {subfig:interface_real_exp2}:} the control interface as presented to the operator in our previous real world experiment. \textbf {\ref {subfig:OCU_exp2}:} the Operator Control Unit (OCU), composed of a laptop, a joystick, a mouse and a screen showing the control interface. The same OCU was used in both experiments. Note that the secondary task cards (i.e cards of 3D objects) were presented on the right hand side of the operators.\relax }}{60}{figure.caption.14}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Note that the simulation recreates the real environment with a good degree of fidelity.\relax }}{60}{figure.caption.15}
\contentsline {figure}{\numberline {4.4}{\ignorespaces \textbf {\ref {subfig:map_exp2}:} laser-derived SLAM map created in the simulation environment. Primary task was to drive from point A to B and back again to A. The yellow shaded region is where artificial sensor noise was introduced. The blue shaded region is where the secondary task was presented to the operator. \textbf {\ref {subfig:map_real_exp2}:} laser-derived SLAM map generated by real robot in our previous experiment. Note the similarities between the real and simulated data.\relax }}{61}{figure.caption.16}
\contentsline {figure}{\numberline {4.5}{\ignorespaces A typical example of a rotated 3D objects card.\relax }}{62}{figure.caption.17}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Primary task results. \textbf {\ref {subfig:totalTime_exp2}:} average time to completion (blue) and score combining time and collisions penalty (green). \textbf {\ref {subfig:totalCollisions_exp2}:} average number of collisions. In all graphs the error bars indicate the standard error.\relax }}{66}{figure.caption.18}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Secondary task performance. \textbf {\ref {subfig:secondary_time_exp2}:} average time to completion for one series of 3D objects. \textbf {\ref {subfig:secondary_mistakes_exp2}:} average number of errors for one series of 3D objects.\relax }}{67}{figure.caption.19}
\contentsline {figure}{\numberline {4.8}{\ignorespaces NASA-TLX score showing the overall trial difficulty as perceived by the operators.\relax }}{68}{figure.caption.20}
\contentsline {figure}{\numberline {4.9}{\ignorespaces \textbf {\ref {subfig:time-percentage-mode_exp2}:} Percentage of time-to-completion spent in each of the two LOAs during the HI trials. Error bars indicate the standard error. \textbf {\ref {subfig:time-percentage-histogram_exp2}:} Histogram showing the proportion of human operators who spent various different proportions of their time in the autonomy LOA during HI experiments.\relax }}{71}{figure.caption.22}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Histogram showing the percentages of human operators who chose to make various different numbers of LOA switches during HI trials.\relax }}{72}{figure.caption.23}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The block diagram of the MI control system. Given a navigation goal; the current pose of the robot; and the map (or a known surrounding area); the expert planner yields a close-to-optimal suggested speed. This speed denotes how fast the robot should be moving towards achieving the navigation goal. Then this speed is compared with the current speed of the robot towards that goal to calculate the raw performance error. The MI controller decides on switching LOA based on the filtered error.\relax }}{81}{figure.caption.24}
\contentsline {figure}{\numberline {5.2}{\ignorespaces \textbf {\ref {subfig:fuzzy_error}:} Membership functions for the linguistic input variable "error". \textbf {\ref {subfig:fuzzy_speed}:} Membership functions for linguistic input variable "speed".\relax }}{85}{figure.caption.25}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Output membership functions.\relax }}{87}{figure.caption.26}
\contentsline {figure}{\numberline {5.4}{\ignorespaces \textbf {\ref {subfig:primary_time_score_exp2_2}:} primary task results; average time to completion (blue) and score (green) combining time and collisions penalty. \textbf {\ref {subfig:secondarytime_exp2_2}:} secondary task time-to-completion. In all graphs the error bars indicate the standard error.\relax }}{91}{figure.caption.29}
\contentsline {figure}{\numberline {5.5}{\ignorespaces \textbf {\ref {subfig:psecondary_mistakes_exp2_2}:} secondary task average number of mistakes/errors. \textbf {\ref {subfig:NASA-TLX_exp2_2}:} NASA-TLX score showing the overall trial difficulty/workload as perceived by the operators.\relax }}{92}{figure.caption.30}
\contentsline {figure}{\numberline {5.6}{\ignorespaces \textbf {\ref {fig:number-loa-switches_exp2_2}:} The average number of LOA switches per control mode. \textbf {\ref {subfig:histogram_lao_hi_exp2_2}:} Histogram showing the number of human operators who chose to make various different numbers of LOA switches during HI.\relax }}{94}{figure.caption.32}
\contentsline {figure}{\numberline {5.7}{\ignorespaces \textbf {\ref {subfig:histogram_lao_mi_exp2_2}:} Histogram showing the number of human operators who chose to make various different numbers of LOA switches during MI. \textbf {\ref {subfig:histogram_lao_mi_ai_exp2_2}:} Histogram showing the number of human operators and the number of LOA switches initiated by the fuzzy MI controller.\relax }}{95}{figure.caption.33}
\contentsline {figure}{\numberline {5.8}{\ignorespaces \ref {subfig:pioneer_exp3}: The pioneer 3DX robot used in the experiment. \ref {subfig:OCU_exp3}: the Operator Control Unit (OCU), composed of a laptop, a joystick, a mouse and a screen showing the control interface. The same OCU was used in all variable autonomy experiments. Note the floor plan in front of the screen, used for the secondary task.\relax }}{99}{figure.caption.34}
\contentsline {figure}{\numberline {5.9}{\ignorespaces The first floor of School of Computer Science, University of Birmingham building, was used as a robot arena for the USAR experiment. \textbf {\ref {subfig:corridor_exp3}:} The long corridor that connected the search areas (i.e. offices). \textbf {\ref {subfig:office_exp3}:} One of the offices used as a search area.\relax }}{100}{figure.caption.35}
\contentsline {figure}{\numberline {5.10}{\ignorespaces \textbf {\ref {subfig:floorplan}:} the floor plan, as kept in the university records, of the area that the experiment took place. This floor plan was printed and given to participants for the secondary task. \textbf {\ref {subfig:floorplan_annotated}:} the floor plan of the experiment area annotated by an operator during the secondary task.\relax }}{101}{figure.caption.36}
\contentsline {figure}{\numberline {5.11}{\ignorespaces \textbf {\ref {subfig:interface_exp3}:} The control interface as presented to the operator. \textbf {Left}: video feed from the camera, the control mode in use and the status of the navigation goal. \textbf {Right}: The map showing the position of the robot (blue footprint and red arrow), the current goal (blue arrow), the AI planned path (green line), the obstacles' laser reflections (red) and the walls (black). \textbf {\ref {subfig:map_exp3}:} The SLAM map of the arena as displayed to the human operator on the interface. Operators had to navigate in turn from point A; to B; to C; to D; and then back again to point A.\relax }}{102}{figure.caption.37}
\contentsline {figure}{\numberline {5.12}{\ignorespaces Two of the hazard signs used in order to denote bio-hazard and radiation risk.\relax }}{103}{figure.caption.38}
\contentsline {figure}{\numberline {5.13}{\ignorespaces \textbf {\ref {subfig:victims}:} The stuffed animals representing the victims of the USAR scenario. A meerkat was representing a victim which is alive and a teddy-bear a victim which is dead. \textbf {\ref {subfig:flammable}:} The hazard sign used to denote flammable materials risk.\relax }}{103}{figure.caption.39}
\contentsline {figure}{\numberline {5.14}{\ignorespaces \textbf {\ref {subfig:primary_metrics_exp3}:} primary task mean time-to-completion (green) and score combining time and collisions penalty (blue). \textbf {\ref {subfig:secondary_time_exp3}:} mean secondary task completion time. In all graphs the error bars indicate the standard error.\relax }}{107}{figure.caption.41}
\contentsline {figure}{\numberline {5.15}{\ignorespaces \textbf {\ref {subfig:nasa-tlx_exp3}:} NASA-TLX score showing the overall trial difficulty-workload as perceived by the operators. \textbf {\ref {subfig:secondary_mistakes_exp3}:} Secondary task total number of errors for each trial.\relax }}{108}{figure.caption.42}
\contentsline {figure}{\numberline {5.16}{\ignorespaces Histogram showing the number of human operators who chose to make various different numbers of LOA switches during HI.\relax }}{109}{figure.caption.43}
\contentsline {figure}{\numberline {5.17}{\ignorespaces \textbf {\ref {subfig:histogram_lao_mi_exp3}:} Histogram showing the number of human operators who chose to make various different numbers of LOA switches during MI. \textbf {\ref {subfig:histogram_lao_mi_ai_exp3}:} Histogram showing the number of human operators and the number of LOA switches initiated by the fuzzy MI controller.\relax }}{110}{figure.caption.44}
\addvspace {10\p@ }
\addvspace {10\p@ }
